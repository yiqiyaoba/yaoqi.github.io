---
layout: post
title: 神经网络常见激活函数总结
mathjax: true
categories: Knowledge
tags: [激活函数]
keywords: relu,sigmod,tanh
description: 总结神经网络中常见的激活函数
---

> template

>神经网络的激活函数是使神经网络模型变得非线性的关键一环，非线性的模型才有能力拟合复杂的模式特征。本文总结常见的激活函数，展示其图像、公式及其导数，并分析其优缺点，相应的使用场景等。

---

参考资料：

- [从ReLU到GELU，一文概览神经网络的激活函数](https://baijiahao.baidu.com/s?id=1653421414340022957&wfr=spider&for=pc )





<img src="https://raw.githubusercontent.com/huangtao36/huangtao36.github.io/master/_posts/which_dir/xxx.png" style="zoom:80%" />

