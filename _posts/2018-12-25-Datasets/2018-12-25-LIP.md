---
layout: post
title: The Look into Person (LIP) Dataset
mathjax: true
categories: Dataset
tags: LIP Dataset Parser
keywords: 
description: Look into Person (LIP) dataset analysis notes.
mermaid: true
status: Completed
---

[The LIP dataset](http://sysu-hcp.net/lip/index.php) is an order of magnitude larger and more challenge than similar previous attempts that contains 50,000 images with elaborated pixel-wise annotations with 19 semantic human part labels and 2D human poses with 16 key points. The images collected from the real-world scenarios contain human appearing with challenging poses and views, heavily occlusions, various appearances and low-resolutions. This challenge and benchmark are fully supported by the Human-Cyber-Physical Intelligence Integration Lab of Sun Yat-sen University.

> 此笔记中的标题即为数据集的文件夹目录索引  
> 注意： 此笔记中所有的 Label 图片的颜色均不能作为像素标准，只是为了直观显示而已。

---

# ATR
## humanparsing
### SegmentationClassAug
17706张人体肢体分割图片，png 格式， shape 大部分为(600,400)， 8.8%的图片大小不一。 像素值范围约为(0, 0.06)，人体的不同块的像素值不一样（同块的像素值完全一样）。

<img src="https://raw.githubusercontent.com/huangtao36/huangtao36.github.io/master/_posts/2018-12-25-Datasets/LIP/ATR_hum_Seg.png" style="zoom:200%" /> 

### JPEGImages
SegmentationClassAug 中对应的RGB图片，jpg 格式。

<img src="https://raw.githubusercontent.com/huangtao36/huangtao36.github.io/master/_posts/2018-12-25-Datasets/LIP/ATR_hum_JPEG.png" style="zoom:200%" /> 

# CIHP
## instance-level_human_parsing

### Training
#### Images
**28280** 张RGB图片，jpg格式，大小不一。

<img src="https://raw.githubusercontent.com/huangtao36/huangtao36.github.io/master/_posts/2018-12-25-Datasets/LIP/CHIP_ins_Train_Images.png" style="zoom:200%" /> 

#### Human
以人为单位的分割 label 图， 对应于 Images

<img src="https://raw.githubusercontent.com/huangtao36/huangtao36.github.io/master/_posts/2018-12-25-Datasets/LIP/CHIP_ins_Train_Human.png" style="zoom:200%" /> 

> Note: 这里的 label 图是 **3** 层的， 即 label.shape == (w, h, 3)。  
> 如下图：  
> <img src="https://raw.githubusercontent.com/huangtao36/huangtao36.github.io/master/_posts/2018-12-25-Datasets/LIP/CHIP_ins_Train_Human_model.png" style="zoom:100%" />  
>    
> 图中有5中颜色的label， 但像素值只有 0 和 0.5019608， 这个 label 是通过 rgb 3层的不同组合区分不同的个体的。 比如红色， 就只有第一层的 label 的位置为0.5019608，其他两层的对应位置是 0。 RGB 三原色，除去 [0, 0, 0] 的组合，就剩下 7 种组合，即是说，一张 label 的图片，最多标记 7 个实例(人)。  


#### Human_ids

这个与上面的 Human 的区别就在于这里的 Label.shape 是 (w, h) 单层的，通过不同的像素值来区分不同实例(人)。
 
<img src="https://raw.githubusercontent.com/huangtao36/huangtao36.github.io/master/_posts/2018-12-25-Datasets/LIP/CHIP_ins_Train_Human_ids.png" style="zoom:200%" /> 

如下图，为一张label图片的实际像素值的 hist 图：

<img src="https://raw.githubusercontent.com/huangtao36/huangtao36.github.io/master/_posts/2018-12-25-Datasets/LIP/CHIP_ins_Train_Human_ids_model_.png" style="zoom:100%" />

#### Categories

这个 Label 是区分人体结构的，不同的身体部位直观上以不同的颜色表示。除了上述的RGB的不同组合外，也有些像素值的不同，有了更大的区分度。 

<img src="https://raw.githubusercontent.com/huangtao36/huangtao36.github.io/master/_posts/2018-12-25-Datasets/LIP/CHIP_ins_Train_Categories.png" style="zoom:200%" /> 


如下图所示，为一张 Label 图中某一部分的三层拆分显示，可以大致看出其组合形式，其中[w, h, 2] 图中钢蓝色部分的像素值为 0.33， 其他图中黄色部分均为1， 其余为0。  

<img src="https://raw.githubusercontent.com/huangtao36/huangtao36.github.io/master/_posts/2018-12-25-Datasets/LIP/CHIP_ins_Train_Categories_all.png" style="zoom:80%" /> 

#### Category_ids

Category_ids类似于 Human_ids, 都是单层的，区分了人体部位，但是不区分哪个人。

#### Instances
与 Categories 相比就是 Instance 是区分人的， 三层。

<img src="https://raw.githubusercontent.com/huangtao36/huangtao36.github.io/master/_posts/2018-12-25-Datasets/LIP/CHIP_ins_Train_Instances.png" style="zoom:100%" /> 

#### Instance_ids
 单层, 区分个人

<img src="https://raw.githubusercontent.com/huangtao36/huangtao36.github.io/master/_posts/2018-12-25-Datasets/LIP/CHIP_ins_Train_Instances_ids.png" style="zoom:100%" /> 

#### train_id.txt
文件名列表， 不包含文件后缀。

### Testing
里面有 Images 文件夹，包含5000张jpg图片，rgb格式。 以及 test_id.txt 文件， 文件名列表，不带后缀。

### Validation
与 Training 完全相同的文件结构。 5000 张。

### human_colormap.mat

猜测这个文件跟之前讨论的各种颜色层有关。但没有具体说明。

### README.md

```python
Images:       images
Category_ids: semantic part segmentation labels         Categories:   visualized semantic part segmentation labels
Human_ids:    semantic person segmentation labels       Human:        visualized semantic person segmentation labels
Instance_ids: instance-level human parsing labels       Instances:    visualized instance-level human parsing labels


Label order of semantic part segmentation:

1.Hat
2.Hair
3.Glove
4.Sunglasses
5.UpperClothes
6.Dress
7.Coat
8.Socks
9.Pants
10.Torso-skin
11.Scarf
12.Skirt
13.Face
14.Left-arm
15.Right-arm
16.Left-leg
17.Right-leg
18.Left-shoe
19.Right-shoe
```


# LIP

## TrainVal_images
### train_images
30462 张rgb图片, jpg格式， 大小不一。 较多为单人图片，也有少量多人，或者只显示人身体的某一部位。

<img src="https://raw.githubusercontent.com/huangtao36/huangtao36.github.io/master/_posts/2018-12-25-Datasets/LIP/LIP_train_images.png" style="zoom:100%" /> 

### train_id.txt
文件名列表，不带后缀

### val_images
10000 张rgb图片, jpg格式， 大小不一

<img src="https://raw.githubusercontent.com/huangtao36/huangtao36.github.io/master/_posts/2018-12-25-Datasets/LIP/LIP_val_images.png" style="zoom:100%" /> 

### val_id.txt
文件名列表，不带后缀

## TrainVal_parsing_annotations 
### train_segmentations
30462 张单层 Label图片，png格式 ，对应于 train_images。 

<img src="https://raw.githubusercontent.com/huangtao36/huangtao36.github.io/master/_posts/2018-12-25-Datasets/LIP/LIP_train_segmentations.png" style="zoom:100%" /> 

### val_segmentations
10000 张单层 Label图片，png格式 ，对应于 val_images。 

<img src="https://raw.githubusercontent.com/huangtao36/huangtao36.github.io/master/_posts/2018-12-25-Datasets/LIP/LIP_val_segmentations.png" style="zoom:100%" /> 

### README_parsing.md
Label order

## TrainVal_pose_annotations
其中包含四个文件， 

```python
'README.md', 
'vis_annotation.py', 
'lip_val_set.csv', 
'lip_train_set.csv'
```

这是人体关节点标注的 annotations. 
其中，README.md 中表示：

```python
csv file line format:
ImageID_PersonId.jpg,x1,y1,v1,x2,y2,v2,...x16,y16,v16
Note: x,y, is the annotation label in (column, row),
      v stands for visuable

Joint order:
    1,R_Ankle
    2,R_Knee
    3,R_Hip
    4,L_Hip
    5,L_Knee
    6,L_Ankle
    7,B_Pelvis
    8,B_Spine
    9,B_Neck
    10,B_Head
    11,R_Wrist
    12,R_Elbow
    13,R_Shoulder
    14,L_Shoulder
    15,L_Elbow
    16,L_Wrist

```
 
使用其中的 vis_annotation.py 代码可以显示出来，文件路径需要修改一下。效果如下：

<img src="https://raw.githubusercontent.com/huangtao36/huangtao36.github.io/master/_posts/2018-12-25-Datasets/LIP/pose.png" style="zoom:150%" /> 

## Testing_images

里面有 testing_mages 文件夹，包含10000张jpg图片，rgb格式。 以及 test_id.txt 文件， 文件名列表，不带后缀。