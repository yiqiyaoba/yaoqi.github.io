---
layout: post
title: The Look into Person (LIP) Dataset
mathjax: true
categories: Dataset
tags: LIP Dataset Parser
keywords: 
description: Look into Person (LIP) dataset analysis notes.
mermaid: true
status: Completed
---

[The LIP dataset](http://sysu-hcp.net/lip/index.php) is an order of magnitude larger and more challenge than similar previous attempts that contains 50,000 images with elaborated pixel-wise annotations with 19 semantic human part labels and 2D human poses with 16 key points. The images collected from the real-world scenarios contain human appearing with challenging poses and views, heavily occlusions, various appearances and low-resolutions. This challenge and benchmark are fully supported by the Human-Cyber-Physical Intelligence Integration Lab of Sun Yat-sen University.

> 此笔记中的标题即为数据集的文件夹目录索引  
> 注意： 此笔记中所有的 Label 图片的颜色均不能作为像素标准，只是为了直观显示而已。

---

# ATR
## humanparsing
### SegmentationClassAug
17706张人体肢体分割图片，png 格式， shape 大部分为(600,400)， 8.8%的图片大小不一。 像素值范围约为(0, 0.06)，人体的不同块的像素值不一样（同块的像素值完全一样）。

<img src="https://raw.githubusercontent.com/huangtao36/huangtao36.github.io/master/_posts/2018-12-25-Datasets/LIP/ATR_hum_Seg.png" style="zoom:200%" /> 

### JPEGImages
SegmentationClassAug 中对应的RGB图片，jpg 格式。

<img src="https://raw.githubusercontent.com/huangtao36/huangtao36.github.io/master/_posts/2018-12-25-Datasets/LIP/ATR_hum_JPEG.png" style="zoom:200%" /> 

# CIHP
## instance-level_human_parsing

### Training
#### Images
28280 张RGB图片，jpg格式，大小不一。

<img src="https://raw.githubusercontent.com/huangtao36/huangtao36.github.io/master/_posts/2018-12-25-Datasets/LIP/CHIP_ins_Train_Images.png" style="zoom:200%" /> 

#### Human
以人为单位的分割 label 图， 对应于 Images

<img src="https://raw.githubusercontent.com/huangtao36/huangtao36.github.io/master/_posts/2018-12-25-Datasets/LIP/CHIP_ins_Train_Human.png" style="zoom:200%" /> 

> Note: 这里的 label 图是 **3** 层的， 即 label.shape == (w, h, 3)。  
> 如下图：  
> <img src="https://raw.githubusercontent.com/huangtao36/huangtao36.github.io/master/_posts/2018-12-25-Datasets/LIP/CHIP_ins_Train_Human_model.png" style="zoom:100%" />  
>    
> 图中有5中颜色的label， 但像素值只有 0 和 0.5019608， 这个 label 是通过 rgb 3层的不同组合区分不同的个体的。 比如红色， 就只有第一层的 label 的位置为0.5019608，其他两层的对应位置是 0。 RGB 三原色，除去 [0, 0, 0] 的组合，就剩下 7 种组合，即是说，一张 label 的图片，最多标记 7 个实例(人)。  


#### Human_ids

这个与上面的 Human 的区别就在于这里的 Label.shape 是 (w, h) 单层的，通过不同的像素值来区分不同实例(人)。
 
<img src="https://raw.githubusercontent.com/huangtao36/huangtao36.github.io/master/_posts/2018-12-25-Datasets/LIP/CHIP_ins_Train_Human_ids.png" style="zoom:200%" /> 

如下图，为一张label图片的实际像素值的 hist 图：

<img src="https://raw.githubusercontent.com/huangtao36/huangtao36.github.io/master/_posts/2018-12-25-Datasets/LIP/CHIP_ins_Train_Human_ids_model_.png" style="zoom:100%" />

#### Categories

这个 Label 是区分人体结构的，不同的身体部位以同一种组合

<img src="https://raw.githubusercontent.com/huangtao36/huangtao36.github.io/master/_posts/2018-12-25-Datasets/LIP/CHIP_ins_Train_Categories.png" style="zoom:200%" /> 

<img src="https://raw.githubusercontent.com/huangtao36/huangtao36.github.io/master/_posts/2018-12-25-Datasets/LIP/CHIP_ins_Train_Categories_all.png" style="zoom:200%" /> 

#### Category_ids

#### Instances
#### Instance_ids

#### train_id.txt

### Testing

### Validation

### human_colormap.mat

### README.md

# LIP
## TrainVal_parsing_annotations
### val_segmentations
### train_segmentations
### README_parsing.md

## TrainVal_images

## TrainVal_pose_annotations

## Testing_images

